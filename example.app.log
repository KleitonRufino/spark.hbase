INFO : 2019-03-19 11:09:30,571 [run-main-0] *** H2Proxy: Driver loaded.
INFO : 2019-03-19 11:09:30,730 [run-main-0] *** H2Proxy: Executed: drop table kv if exists; with result: 0
INFO : 2019-03-19 11:09:30,733 [run-main-0] *** H2Proxy: Executed: create table kv (key varchar(64) not null, value varchar(64) not null); with result: 0
WARN : 2019-03-19 11:09:30,975 [run-main-0] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
INFO : 2019-03-19 11:09:31,326 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:host.name=172.17.128.124
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.version=1.8.0_202
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.vendor=Oracle Corporation
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/jre
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.class.path=/usr/local/Cellar/sbt/1.2.8/libexec/bin/sbt-launch.jar
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.library.path=/Users/objektwerks/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.io.tmpdir=/var/folders/cd/1wkmn_gn2d164ch7c66b_46h0000gn/T/
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:java.compiler=<NA>
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:os.name=Mac OS X
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:os.arch=x86_64
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:os.version=10.14.3
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:user.name=objektwerks
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:user.home=/Users/objektwerks
INFO : 2019-03-19 11:09:31,327 [ReadOnlyZKClient-localhost:2181@0x55267052] Client environment:user.dir=/Users/objektwerks/workspace/spark.hbase
INFO : 2019-03-19 11:09:31,329 [ReadOnlyZKClient-localhost:2181@0x55267052] Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$4752/120430824@9309b29
INFO : 2019-03-19 11:09:36,354 [ReadOnlyZKClient-localhost:2181@0x55267052-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] Opening socket connection to server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181. Will not attempt to authenticate using SASL (unknown error)
INFO : 2019-03-19 11:09:36,376 [ReadOnlyZKClient-localhost:2181@0x55267052-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] Socket connection established to fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181, initiating session
INFO : 2019-03-19 11:09:36,386 [ReadOnlyZKClient-localhost:2181@0x55267052-SendThread(fe80:0:0:0:0:0:0:1%1:2181)] Session establishment complete on server fe80:0:0:0:0:0:0:1%1/fe80:0:0:0:0:0:0:1%1:2181, sessionid = 0x16995d997c5002e, negotiated timeout = 40000
INFO : 2019-03-19 11:09:36,554 [run-main-0] *** HBaseProxy: Connection created.
INFO : 2019-03-19 11:09:37,063 [run-main-0] Started disable of kv
INFO : 2019-03-19 11:09:37,513 [run-main-0] Operation: DISABLE, Table Name: default:kv, procId: 111 completed
INFO : 2019-03-19 11:09:37,742 [run-main-0] Operation: DELETE, Table Name: default:kv, procId: 113 completed
INFO : 2019-03-19 11:09:37,742 [run-main-0] *** HBaseProxy: Dropped table: kv
INFO : 2019-03-19 11:09:38,595 [run-main-0] Operation: CREATE, Table Name: default:kv, procId: 114 completed
INFO : 2019-03-19 11:09:38,595 [run-main-0] *** HBaseProxy: Created table: kv
INFO : 2019-03-19 11:09:39,224 [run-main-0] *** HBaseProxy: Put 10 rows to table: kv
INFO : 2019-03-19 11:09:39,243 [run-main-0] *** HBaseProxy: Scan 10 rows from table: kv
INFO : 2019-03-19 11:09:39,251 [run-main-0] *** HBaseProxy: Row Keys: ArrayBuffer(1, 10, 2, 3, 4, 5, 6, 7, 8, 9)
INFO : 2019-03-19 11:09:39,434 [run-main-0] Running Spark version 2.4.0
INFO : 2019-03-19 11:09:39,461 [run-main-0] Submitted application: spark.hbase
INFO : 2019-03-19 11:09:39,525 [run-main-0] Changing view acls to: objektwerks
INFO : 2019-03-19 11:09:39,526 [run-main-0] Changing modify acls to: objektwerks
INFO : 2019-03-19 11:09:39,526 [run-main-0] Changing view acls groups to: 
INFO : 2019-03-19 11:09:39,527 [run-main-0] Changing modify acls groups to: 
INFO : 2019-03-19 11:09:39,527 [run-main-0] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(objektwerks); groups with view permissions: Set(); users  with modify permissions: Set(objektwerks); groups with modify permissions: Set()
INFO : 2019-03-19 11:09:39,802 [run-main-0] Successfully started service 'sparkDriver' on port 55617.
INFO : 2019-03-19 11:09:39,831 [run-main-0] Registering MapOutputTracker
INFO : 2019-03-19 11:09:39,852 [run-main-0] Registering BlockManagerMaster
INFO : 2019-03-19 11:09:39,855 [run-main-0] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
INFO : 2019-03-19 11:09:39,856 [run-main-0] BlockManagerMasterEndpoint up
INFO : 2019-03-19 11:09:39,868 [run-main-0] Created local directory at /private/var/folders/cd/1wkmn_gn2d164ch7c66b_46h0000gn/T/blockmgr-6b22ec72-efa3-43f7-9794-2696de916090
INFO : 2019-03-19 11:09:39,895 [run-main-0] MemoryStore started with capacity 2004.6 MB
INFO : 2019-03-19 11:09:39,910 [run-main-0] Registering OutputCommitCoordinator
INFO : 2019-03-19 11:09:40,007 [run-main-0] Logging initialized @34324ms
INFO : 2019-03-19 11:09:40,070 [run-main-0] jetty-9.3.z-SNAPSHOT, build timestamp: 2018-09-04T17:11:46-04:00, git hash: 3ce520221d0240229c862b122d2b06c12a625732
INFO : 2019-03-19 11:09:40,088 [run-main-0] Started @34405ms
INFO : 2019-03-19 11:09:40,107 [run-main-0] Started ServerConnector@4a03d342{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
INFO : 2019-03-19 11:09:40,108 [run-main-0] Successfully started service 'SparkUI' on port 4040.
INFO : 2019-03-19 11:09:40,126 [run-main-0] Started o.s.j.s.ServletContextHandler@1d3d72c{/jobs,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,127 [run-main-0] Started o.s.j.s.ServletContextHandler@2e886723{/jobs/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,127 [run-main-0] Started o.s.j.s.ServletContextHandler@54c7378{/jobs/job,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,128 [run-main-0] Started o.s.j.s.ServletContextHandler@14ccb6d4{/jobs/job/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,129 [run-main-0] Started o.s.j.s.ServletContextHandler@79107a11{/stages,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,129 [run-main-0] Started o.s.j.s.ServletContextHandler@1f2111f8{/stages/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,130 [run-main-0] Started o.s.j.s.ServletContextHandler@1bd67786{/stages/stage,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,131 [run-main-0] Started o.s.j.s.ServletContextHandler@7de5ab3{/stages/stage/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,132 [run-main-0] Started o.s.j.s.ServletContextHandler@2f9c6789{/stages/pool,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,132 [run-main-0] Started o.s.j.s.ServletContextHandler@2d0216bc{/stages/pool/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,133 [run-main-0] Started o.s.j.s.ServletContextHandler@4f0cf8d{/storage,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,134 [run-main-0] Started o.s.j.s.ServletContextHandler@718e1662{/storage/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,134 [run-main-0] Started o.s.j.s.ServletContextHandler@3d6287f5{/storage/rdd,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,135 [run-main-0] Started o.s.j.s.ServletContextHandler@68d113{/storage/rdd/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,136 [run-main-0] Started o.s.j.s.ServletContextHandler@2e6fa34{/environment,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,137 [run-main-0] Started o.s.j.s.ServletContextHandler@35ac10c{/environment/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,138 [run-main-0] Started o.s.j.s.ServletContextHandler@2aaea3bd{/executors,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,139 [run-main-0] Started o.s.j.s.ServletContextHandler@6c080fb2{/executors/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,139 [run-main-0] Started o.s.j.s.ServletContextHandler@590a6f5d{/executors/threadDump,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,140 [run-main-0] Started o.s.j.s.ServletContextHandler@c0d97d1{/executors/threadDump/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,148 [run-main-0] Started o.s.j.s.ServletContextHandler@53e16ea6{/static,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,149 [run-main-0] Started o.s.j.s.ServletContextHandler@66958ba1{/,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,150 [run-main-0] Started o.s.j.s.ServletContextHandler@65a8b037{/api,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,151 [run-main-0] Started o.s.j.s.ServletContextHandler@2f6e0092{/jobs/job/kill,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,151 [run-main-0] Started o.s.j.s.ServletContextHandler@7555a170{/stages/stage/kill,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,153 [run-main-0] Bound SparkUI to 0.0.0.0, and started at http://172.17.128.124:4040
INFO : 2019-03-19 11:09:40,273 [run-main-0] Starting executor ID driver on host localhost
INFO : 2019-03-19 11:09:40,298 [run-main-0] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55618.
INFO : 2019-03-19 11:09:40,298 [run-main-0] Server created on 172.17.128.124:55618
INFO : 2019-03-19 11:09:40,300 [run-main-0] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
INFO : 2019-03-19 11:09:40,327 [run-main-0] Registering BlockManager BlockManagerId(driver, 172.17.128.124, 55618, None)
INFO : 2019-03-19 11:09:40,333 [dispatcher-event-loop-2] Registering block manager 172.17.128.124:55618 with 2004.6 MB RAM, BlockManagerId(driver, 172.17.128.124, 55618, None)
INFO : 2019-03-19 11:09:40,336 [run-main-0] Registered BlockManager BlockManagerId(driver, 172.17.128.124, 55618, None)
INFO : 2019-03-19 11:09:40,336 [run-main-0] Initialized BlockManager: BlockManagerId(driver, 172.17.128.124, 55618, None)
INFO : 2019-03-19 11:09:40,353 [run-main-0] Started o.s.j.s.ServletContextHandler@2bf3fe{/metrics/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:40,458 [run-main-0] *** SparkHBaseH2App: Created Spark session.
INFO : 2019-03-19 11:09:42,097 [run-main-0] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/objektwerks/workspace/spark.hbase/spark-warehouse').
INFO : 2019-03-19 11:09:42,097 [run-main-0] Warehouse path is 'file:/Users/objektwerks/workspace/spark.hbase/spark-warehouse'.
INFO : 2019-03-19 11:09:42,109 [run-main-0] Started o.s.j.s.ServletContextHandler@3a76dbf1{/SQL,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:42,110 [run-main-0] Started o.s.j.s.ServletContextHandler@2357372d{/SQL/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:42,111 [run-main-0] Started o.s.j.s.ServletContextHandler@18e29548{/SQL/execution,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:42,111 [run-main-0] Started o.s.j.s.ServletContextHandler@56c08b22{/SQL/execution/json,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:42,113 [run-main-0] Started o.s.j.s.ServletContextHandler@36beabbc{/static/sql,null,AVAILABLE,@Spark}
INFO : 2019-03-19 11:09:42,629 [run-main-0] Registered StateStoreCoordinator endpoint
INFO : 2019-03-19 11:09:42,881 [run-main-0] Code generated in 211.137056 ms
INFO : 2019-03-19 11:09:43,639 [run-main-0] Code generated in 10.398467 ms
INFO : 2019-03-19 11:09:43,780 [run-main-0] Starting job: foreach at SparkHBaseH2App.scala:31
INFO : 2019-03-19 11:09:43,802 [dag-scheduler-event-loop] Got job 0 (foreach at SparkHBaseH2App.scala:31) with 8 output partitions
INFO : 2019-03-19 11:09:43,802 [dag-scheduler-event-loop] Final stage: ResultStage 0 (foreach at SparkHBaseH2App.scala:31)
INFO : 2019-03-19 11:09:43,802 [dag-scheduler-event-loop] Parents of final stage: List()
INFO : 2019-03-19 11:09:43,804 [dag-scheduler-event-loop] Missing parents: List()
INFO : 2019-03-19 11:09:43,810 [dag-scheduler-event-loop] Submitting ResultStage 0 (MapPartitionsRDD[3] at foreach at SparkHBaseH2App.scala:31), which has no missing parents
INFO : 2019-03-19 11:09:43,913 [dag-scheduler-event-loop] Block broadcast_0 stored as values in memory (estimated size 6.7 KB, free 2004.6 MB)
INFO : 2019-03-19 11:09:43,948 [dag-scheduler-event-loop] Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2004.6 MB)
INFO : 2019-03-19 11:09:43,950 [dispatcher-event-loop-5] Added broadcast_0_piece0 in memory on 172.17.128.124:55618 (size: 3.4 KB, free: 2004.6 MB)
INFO : 2019-03-19 11:09:43,952 [dag-scheduler-event-loop] Created broadcast 0 from broadcast at DAGScheduler.scala:1161
INFO : 2019-03-19 11:09:43,966 [dag-scheduler-event-loop] Submitting 8 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at foreach at SparkHBaseH2App.scala:31) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
INFO : 2019-03-19 11:09:43,967 [dag-scheduler-event-loop] Adding task set 0.0 with 8 tasks
INFO : 2019-03-19 11:09:44,335 [dispatcher-event-loop-6] Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,339 [dispatcher-event-loop-6] Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,340 [dispatcher-event-loop-6] Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,340 [dispatcher-event-loop-6] Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7572 bytes)
INFO : 2019-03-19 11:09:44,341 [dispatcher-event-loop-6] Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,342 [dispatcher-event-loop-6] Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,342 [dispatcher-event-loop-6] Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 7531 bytes)
INFO : 2019-03-19 11:09:44,343 [dispatcher-event-loop-6] Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 7572 bytes)
INFO : 2019-03-19 11:09:44,355 [Executor task launch worker for task 2] Running task 2.0 in stage 0.0 (TID 2)
INFO : 2019-03-19 11:09:44,355 [Executor task launch worker for task 5] Running task 5.0 in stage 0.0 (TID 5)
INFO : 2019-03-19 11:09:44,356 [Executor task launch worker for task 1] Running task 1.0 in stage 0.0 (TID 1)
INFO : 2019-03-19 11:09:44,357 [Executor task launch worker for task 3] Running task 3.0 in stage 0.0 (TID 3)
INFO : 2019-03-19 11:09:44,357 [Executor task launch worker for task 7] Running task 7.0 in stage 0.0 (TID 7)
INFO : 2019-03-19 11:09:44,358 [Executor task launch worker for task 4] Running task 4.0 in stage 0.0 (TID 4)
INFO : 2019-03-19 11:09:44,360 [Executor task launch worker for task 0] Running task 0.0 in stage 0.0 (TID 0)
INFO : 2019-03-19 11:09:44,361 [Executor task launch worker for task 6] Running task 6.0 in stage 0.0 (TID 6)
INFO : 2019-03-19 11:09:44,862 [Executor task launch worker for task 0] Code generated in 25.906949 ms
INFO : 2019-03-19 11:09:44,875 [Executor task launch worker for task 5] *** HBaseProxy: Get 6 from table: kv with value: {"key":"6","value":"6"}
INFO : 2019-03-19 11:09:44,876 [Executor task launch worker for task 2] *** HBaseProxy: Get 2 from table: kv with value: {"key":"2","value":"2"}
INFO : 2019-03-19 11:09:44,876 [Executor task launch worker for task 0] *** HBaseProxy: Get 1 from table: kv with value: {"key":"1","value":"1"}
INFO : 2019-03-19 11:09:44,878 [Executor task launch worker for task 3] *** HBaseProxy: Get 3 from table: kv with value: {"key":"3","value":"3"}
INFO : 2019-03-19 11:09:44,878 [Executor task launch worker for task 6] *** HBaseProxy: Get 7 from table: kv with value: {"key":"7","value":"7"}
INFO : 2019-03-19 11:09:44,879 [Executor task launch worker for task 1] *** HBaseProxy: Get 10 from table: kv with value: {"key":"10","value":"10"}
INFO : 2019-03-19 11:09:44,879 [Executor task launch worker for task 4] *** HBaseProxy: Get 5 from table: kv with value: {"key":"5","value":"5"}
INFO : 2019-03-19 11:09:44,879 [Executor task launch worker for task 7] *** HBaseProxy: Get 8 from table: kv with value: {"key":"8","value":"8"}
INFO : 2019-03-19 11:09:44,899 [Executor task launch worker for task 3] *** H2Proxy: Executed: insert into kv values(3, 3) with result: 1
INFO : 2019-03-19 11:09:44,900 [Executor task launch worker for task 1] *** H2Proxy: Executed: insert into kv values(10, 10) with result: 1
INFO : 2019-03-19 11:09:44,900 [Executor task launch worker for task 5] *** H2Proxy: Executed: insert into kv values(6, 6) with result: 1
INFO : 2019-03-19 11:09:44,901 [Executor task launch worker for task 0] *** H2Proxy: Executed: insert into kv values(1, 1) with result: 1
INFO : 2019-03-19 11:09:44,902 [Executor task launch worker for task 6] *** H2Proxy: Executed: insert into kv values(7, 7) with result: 1
INFO : 2019-03-19 11:09:44,902 [Executor task launch worker for task 2] *** H2Proxy: Executed: insert into kv values(2, 2) with result: 1
INFO : 2019-03-19 11:09:44,903 [Executor task launch worker for task 3] *** HBaseProxy: Get 4 from table: kv with value: {"key":"4","value":"4"}
INFO : 2019-03-19 11:09:44,903 [Executor task launch worker for task 7] *** H2Proxy: Executed: insert into kv values(8, 8) with result: 1
INFO : 2019-03-19 11:09:44,904 [Executor task launch worker for task 4] *** H2Proxy: Executed: insert into kv values(5, 5) with result: 1
INFO : 2019-03-19 11:09:44,904 [Executor task launch worker for task 3] *** H2Proxy: Executed: insert into kv values(4, 4) with result: 1
INFO : 2019-03-19 11:09:44,907 [Executor task launch worker for task 7] *** HBaseProxy: Get 9 from table: kv with value: {"key":"9","value":"9"}
INFO : 2019-03-19 11:09:44,908 [Executor task launch worker for task 7] *** H2Proxy: Executed: insert into kv values(9, 9) with result: 1
INFO : 2019-03-19 11:09:44,921 [Executor task launch worker for task 2] Finished task 2.0 in stage 0.0 (TID 2). 937 bytes result sent to driver
INFO : 2019-03-19 11:09:44,922 [Executor task launch worker for task 3] Finished task 3.0 in stage 0.0 (TID 3). 980 bytes result sent to driver
INFO : 2019-03-19 11:09:44,922 [Executor task launch worker for task 4] Finished task 4.0 in stage 0.0 (TID 4). 980 bytes result sent to driver
INFO : 2019-03-19 11:09:44,922 [Executor task launch worker for task 7] Finished task 7.0 in stage 0.0 (TID 7). 980 bytes result sent to driver
INFO : 2019-03-19 11:09:44,921 [Executor task launch worker for task 5] Finished task 5.0 in stage 0.0 (TID 5). 980 bytes result sent to driver
INFO : 2019-03-19 11:09:44,921 [Executor task launch worker for task 0] Finished task 0.0 in stage 0.0 (TID 0). 937 bytes result sent to driver
INFO : 2019-03-19 11:09:44,922 [Executor task launch worker for task 6] Finished task 6.0 in stage 0.0 (TID 6). 937 bytes result sent to driver
INFO : 2019-03-19 11:09:44,923 [Executor task launch worker for task 1] Finished task 1.0 in stage 0.0 (TID 1). 937 bytes result sent to driver
INFO : 2019-03-19 11:09:44,931 [task-result-getter-0] Finished task 2.0 in stage 0.0 (TID 2) in 591 ms on localhost (executor driver) (1/8)
INFO : 2019-03-19 11:09:44,935 [task-result-getter-2] Finished task 4.0 in stage 0.0 (TID 4) in 594 ms on localhost (executor driver) (2/8)
INFO : 2019-03-19 11:09:44,936 [task-result-getter-1] Finished task 3.0 in stage 0.0 (TID 3) in 595 ms on localhost (executor driver) (3/8)
INFO : 2019-03-19 11:09:44,936 [task-result-getter-3] Finished task 7.0 in stage 0.0 (TID 7) in 593 ms on localhost (executor driver) (4/8)
INFO : 2019-03-19 11:09:44,938 [task-result-getter-0] Finished task 5.0 in stage 0.0 (TID 5) in 597 ms on localhost (executor driver) (5/8)
INFO : 2019-03-19 11:09:44,939 [task-result-getter-2] Finished task 0.0 in stage 0.0 (TID 0) in 936 ms on localhost (executor driver) (6/8)
INFO : 2019-03-19 11:09:44,939 [task-result-getter-1] Finished task 6.0 in stage 0.0 (TID 6) in 597 ms on localhost (executor driver) (7/8)
INFO : 2019-03-19 11:09:44,940 [task-result-getter-3] Finished task 1.0 in stage 0.0 (TID 1) in 602 ms on localhost (executor driver) (8/8)
INFO : 2019-03-19 11:09:44,941 [task-result-getter-3] Removed TaskSet 0.0, whose tasks have all completed, from pool 
INFO : 2019-03-19 11:09:44,950 [dag-scheduler-event-loop] ResultStage 0 (foreach at SparkHBaseH2App.scala:31) finished in 1.118 s
INFO : 2019-03-19 11:09:44,954 [run-main-0] Job 0 finished: foreach at SparkHBaseH2App.scala:31, took 1.174409 s
INFO : 2019-03-19 11:09:44,968 [run-main-0] Stopped Spark@4a03d342{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
INFO : 2019-03-19 11:09:44,969 [run-main-0] Stopped Spark web UI at http://172.17.128.124:4040
INFO : 2019-03-19 11:09:44,991 [dispatcher-event-loop-7] MapOutputTrackerMasterEndpoint stopped!
INFO : 2019-03-19 11:09:45,009 [run-main-0] MemoryStore cleared
INFO : 2019-03-19 11:09:45,010 [run-main-0] BlockManager stopped
INFO : 2019-03-19 11:09:45,015 [run-main-0] BlockManagerMaster stopped
INFO : 2019-03-19 11:09:45,017 [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
INFO : 2019-03-19 11:09:45,029 [run-main-0] Successfully stopped SparkContext
INFO : 2019-03-19 11:09:45,029 [run-main-0] *** SparkHBaseH2App: Closed Spark session.
INFO : 2019-03-19 11:09:45,029 [run-main-0] *** SparkHBaseH2App: Job succeeded!
INFO : 2019-03-19 11:09:45,029 [run-main-0] Closing master protocol: MasterService
INFO : 2019-03-19 11:09:45,031 [run-main-0] *** HBaseProxy: Connection closed.
INFO : 2019-03-19 11:09:45,035 [ReadOnlyZKClient-localhost:2181@0x55267052] Session: 0x16995d997c5002e closed
INFO : 2019-03-19 11:09:45,035 [ReadOnlyZKClient-localhost:2181@0x55267052-EventThread] EventThread shut down for session: 0x16995d997c5002e
INFO : 2019-03-19 11:09:45,116 [Thread-5] Shutdown hook called
INFO : 2019-03-19 11:09:45,117 [Thread-5] Deleting directory /private/var/folders/cd/1wkmn_gn2d164ch7c66b_46h0000gn/T/spark-80c01b50-d979-4c82-98c8-fe17c6deb40d
